
/*******************************************************************************************

File Name       :   CSLAB_FPGROWTH_EXAMPLE_V1
Purpose 	:   Code for FP Growth in Scala
Author		:   Durga Prasad
Reviewer 	:   Jothi Periasamy
Date and Time	:   01/22/2015 13:12 hrs
Version		:   1.0	
Change History 	: 

____________________________________________________________________________________________

	Who				   When 			  Why
____________________________________________________________________________________________


	DP				01/22/2015		    Initital Release 

____________________________________________________________________________________________


/*******************************************************************************************

  package org.apache.spark.examples.mllib

  import scopt.OptionParser

  import org.apache.spark.{SparkConf, SparkContext}

  import org.apache.spark.mllib.fpm.FPGrowth

  object FPGrowthExample {

  case class Params(
    
  input: String = null,
    
  minSupport: Double = 0.3,
    
  numPartition: Int = -1) extends AbstractParams[Params]

  def main(args: Array[String]) {
    
  val defaultParams = Params()

  val parser = new OptionParser[Params]("FPGrowthExample") {
  
  head("FPGrowth: an example FP-growth app.")
  
  opt[Double]("minSupport")
  
  .text(s"minimal support level, default: ${defaultParams.minSupport}")
  
  .action((x, c) => c.copy(minSupport = x))
  
  opt[Int]("numPartition")
  
  .text(s"number of partition, default: ${defaultParams.numPartition}")
  
  .action((x, c) => c.copy(numPartition = x))
  
   arg[String]("<input>")
  
  .text("input paths to input data set, whose file format is that each line " +
  
  "contains a transaction with each item in String and separated by a space")
  
  .required()

  .action((x, c) => c.copy(input = x))
    
   }

  parser.parse(args, defaultParams).map { params =>
  
  run(params)
   
  }.getOrElse {
      
  sys.exit(1)
    
  }
  
  }

  def run(params: Params) {
    
  val conf = new SparkConf().setAppName(s"FPGrowthExample with $params")
    
  val sc = new SparkContext(conf)
    
  val transactions = sc.textFile(params.input).map(_.split(" ")).cache()

  println(s"Number of transactions: ${transactions.count()}")

  val model = new FPGrowth()
  
  .setMinSupport(params.minSupport)
  
  .setNumPartitions(params.numPartition)

  .run(transactions)

   println(s"Number of frequent itemsets: ${model.freqItemsets.count()}")

   model.freqItemsets.collect().foreach { itemset =>
   
   println(itemset.items.mkString("[", ",", "]") + ", " + itemset.freq)
    
   }

   sc.stop()
  
   }

   }

/*******************************************************************************************
  Disclaimer.

      We are providing this code block strictly for learning and researching, this is not a 
production ready code. We have no liability on this particular code under any circumstances; 
users should use this code on their own risk. All software, hardware and othr products that 
are referenced in these materials belong to the respective vendor who developed or who owns 
this product.

/*******************************************************************************************
  
