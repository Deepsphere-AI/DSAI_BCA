
/*******************************************************************************************

File Name       :   CSLAB_TFIDF_VECTORIZER_V1
Purpose 	:   A Program for Tfidf Vectorizer in Scala
Author		:   Durga Prasad
Reviewer 	:   Jothi Periasamy
Date and Time	:   11/02/2019 16:21 hrs
Version		:   1.0	
Change History 	: 

____________________________________________________________________________________________

	Who				   When 			  Why
____________________________________________________________________________________________


	DP				11/02/2019		    Initital Release 

____________________________________________________________________________________________


/*******************************************************************************************

## Program Description : A Program for Tfidf Vectorizer in Scala

## Scala Development Environment & Runtime - Eclipse IDE, Anaconda, Jupyter

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.mllib.feature.{HashingTF, IDF}
import org.apache.spark.mllib.linalg.Vector
import org.apache.spark.rdd.RDD

object TFIDFExample {

  def main(args: Array[String]): Unit = {

    val vAR_CSLAB_conf = new SparkConf().setAppName("TFIDFExample")

    var vAR_CSLAB_ENV_PATH = sys.env("SCALA_TUTORIAL_PATH2")
       
    var vAR_CSLAB_DATA_FILE =  "kmeans_data.txt";
      
    var vAR_CSLAB_FILE_PATH =  vAR_CSLAB_ENV_PATH + vAR_CSLAB_DATA_FILE 
      
    // Load documents (one per line).
    val vAR_CSLAB_documents: RDD[Seq[String]] = sc.textFile(vAR_CSLAB_FILE_PATH)
      .map(_.split(" ").toSeq)

    val vAR_CSLAB_hashingTF = new HashingTF()
      
    val vAR_CSLAB_tf: RDD[Vector] = vAR_CSLAB_hashingTF.transform(vAR_CSLAB_documents)

    // While applying HashingTF only needs a single pass to the data, applying IDF needs two passes:
    // First to compute the IDF vector and second to scale the term frequencies by IDF.
    vAR_CSLAB_tf.cache()
      
    val vAR_CSLAB_idf = new IDF().fit(vAR_CSLAB_tf)
      
    val vAR_CSLAB_tfidf: RDD[Vector] = vAR_CSLAB_idf.transform(vAR_CSLAB_tf)

    // spark.mllib IDF implementation provides an option for ignoring terms which occur in less than
    // a minimum number of documents. In such cases, the IDF for these terms is set to 0.
    // This feature can be used by passing the minDocFreq value to the IDF constructor.
    val vAR_CSLAB_idfIgnore = new IDF(minDocFreq = 2).fit(vAR_CSLAB_tf)
      
    val vAR_CSLAB_tfidfIgnore: RDD[Vector] = vAR_CSLAB_idfIgnore.transform(vAR_CSLAB_tf)

    println("tfidf: ")
      
    vAR_CSLAB_tfidf.foreach(vAR_CSLAB_x => println(vAR_CSLAB_x))

    println("tfidfIgnore: ")
      
    vAR_CSLAB_tfidfIgnore.foreach(vAR_CSLAB_x => println(vAR_CSLAB_x))
      
  }
    
}

TFIDFExample.main(Array(""))
	 
/*******************************************************************************************
  Disclaimer.

      We are providing this code block strictly for learning and researching, this is not a 
production ready code. We have no liability on this particular code under any circumstances; 
users should use this code on their own risk. All software, hardware and othr products that 
are referenced in these materials belong to the respective vendor who developed or who owns 
this product.

/*******************************************************************************************
  