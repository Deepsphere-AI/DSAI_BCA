
/*******************************************************************************************

File Name       :   CSLAB_PRINCIPAL_COMPONENT_ANALYSIS_V1
Purpose 	:   A Program for Principal Component Analysis in Scala
Author		:   Durga Prasad
Reviewer 	:   Jothi Periasamy
Date and Time	:   08/02/2019 14:22 hrs
Version		:   1.0	
Change History 	: 

____________________________________________________________________________________________

	Who				   When 			  Why
____________________________________________________________________________________________


	DP				08/02/2019		    Initital Release 

____________________________________________________________________________________________


/*******************************************************************************************

## Program Description : A Program for Principal Component Analysis in Scala

## Scala Development Environment & Runtime - Eclipse IDE, Anaconda, Jupyter

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.mllib.feature.PCA
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.regression.{LabeledPoint, LinearRegressionWithSGD}

@deprecated("Deprecated since LinearRegressionWithSGD is deprecated.  Use ml.feature.PCA", "2.0.0")
object PCAExample {

  def main(args: Array[String]): Unit = {

    val vAR_CSLAB_conf = new SparkConf().setAppName("PCAExample")
    
    var vAR_CSLAB_ENV_PATH = sys.env("SCALA_TUTORIAL_PATH2")
       
    var vAR_CSLAB_DATA_FILE =  "ridge-data/lpsa.data";
      
    var vAR_CSLAB_FILE_PATH =  vAR_CSLAB_ENV_PATH + vAR_CSLAB_DATA_FILE
      
    val vAR_CSLAB_data = sc.textFile(vAR_CSLAB_FILE_PATH).map { line =>
        
      val vAR_CSLAB_parts = line.split(',')
        
      LabeledPoint(vAR_CSLAB_parts(0).toDouble, Vectors.dense(vAR_CSLAB_parts(1).split(' ').map(_.toDouble)))
        
    }.cache()

    val vAR_CSLAB_splits = vAR_CSLAB_data.randomSplit(Array(0.6, 0.4), seed = 11L)
      
    val vAR_CSLAB_training = vAR_CSLAB_splits(0).cache()
      
    val vAR_CSLAB_test = vAR_CSLAB_splits(1)

    val vAR_CSLAB_pca = new PCA(vAR_CSLAB_training.first().features.size / 2).fit(vAR_CSLAB_data.map(_.features))
      
    val vAR_CSLAB_training_pca = vAR_CSLAB_training.map(vAR_CSLAB_p => vAR_CSLAB_p.copy(features = vAR_CSLAB_pca.transform(vAR_CSLAB_p.features)))
      
    val vAR_CSLAB_test_pca = vAR_CSLAB_test.map(vAR_CSLAB_p => vAR_CSLAB_p.copy(features = vAR_CSLAB_pca.transform(vAR_CSLAB_p.features)))

    val vAR_CSLAB_numIterations = 100
      
    val vAR_CSLAB_model = LinearRegressionWithSGD.train(vAR_CSLAB_training, vAR_CSLAB_numIterations)
      
    val vAR_CSLAB_model_pca = LinearRegressionWithSGD.train(vAR_CSLAB_training_pca, vAR_CSLAB_numIterations)

    val vAR_CSLAB_valuesAndPreds = vAR_CSLAB_test.map { vAR_CSLAB_point =>
      val vAR_CSLAB_score = vAR_CSLAB_model.predict(vAR_CSLAB_point.features)
      (vAR_CSLAB_score, vAR_CSLAB_point.label)
    }

    val vAR_CSLAB_valuesAndPreds_pca = vAR_CSLAB_test_pca.map { vAR_CSLAB_point =>
      val vAR_CSLAB_score = vAR_CSLAB_model_pca.predict(vAR_CSLAB_point.features)
      (vAR_CSLAB_score, vAR_CSLAB_point.label)
    }

    val vAR_CSLAB_MSE = vAR_CSLAB_valuesAndPreds.map { case (v, vAR_CSLAB_p) => math.pow((v - vAR_CSLAB_p), 2) }.mean()
    val vAR_CSLAB_MSE_pca = vAR_CSLAB_valuesAndPreds_pca.map { case (v, vAR_CSLAB_p) => math.pow((v - vAR_CSLAB_p), 2) }.mean()

    println(s"Mean Squared Error = $vAR_CSLAB_MSE")
    println(s"PCA Mean Squared Error = $vAR_CSLAB_MSE_pca")

  }
    
}

PCAExample.main(Array(" "))
	 
/*******************************************************************************************
  Disclaimer.

      We are providing this code block strictly for learning and researching, this is not a 
production ready code. We have no liability on this particular code under any circumstances; 
users should use this code on their own risk. All software, hardware and othr products that 
are referenced in these materials belong to the respective vendor who developed or who owns 
this product.

/*******************************************************************************************
  